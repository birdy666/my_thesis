{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import torch.optim as optim\n",
    "import fasttext\n",
    "from datetime import datetime\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import grad\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from skimage import io\n",
    "from math import sin, cos, pi\n",
    "\n",
    "from model import *\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nstart_from_epoch = 1\\ntorch.save(modelA.state_dict(), path +\"testModel\" + \\'_\\' + f\\'{start_from_epoch:05d}\\')\\n\\nmodelB = ModelA()\\nif start_from_epoch > 0:\\n    modelB.load_state_dict(torch.load(path +\"testModel\" + \\'_\\' + f\\'{start_from_epoch:05d}\\'), False)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/birdy/code/master-thesis/\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "keypoint_threshold = 7\n",
    "\n",
    "\"\"\"  \n",
    "start_from_epoch = 1\n",
    "torch.save(modelA.state_dict(), path +\"testModel\" + '_' + f'{start_from_epoch:05d}')\n",
    "\n",
    "modelB = ModelA()\n",
    "if start_from_epoch > 0:\n",
    "    modelB.load_state_dict(torch.load(path +\"testModel\" + '_' + f'{start_from_epoch:05d}'), False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataset that constructs heatmaps and optional matching caption encodings tensors on the fly\n",
    "class HeatmapDataset(torch.utils.data.Dataset):\n",
    "    # a dataset contains keypoints and captions, can add sentence encoding\n",
    "    def __init__(self, coco_keypoint, coco_caption, single_person=False, text_model=None, full_image=False,\n",
    "                 for_regression=False):\n",
    "\n",
    "        # get all containing 'person' image ids\n",
    "        image_ids = coco_keypoint.getImgIds()\n",
    "\n",
    "        self.with_vector = (text_model is not None)\n",
    "        self.for_regression = for_regression\n",
    "        if for_regression:\n",
    "            full_image = False\n",
    "        self.full_image = full_image\n",
    "        self.dataset = []\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            keypoint_ids = coco_keypoint.getAnnIds(imgIds=image_id)\n",
    "            if len(keypoint_ids) > 0 and ((single_person and len(keypoint_ids) == 1) or (not single_person)):\n",
    "                caption_ids = coco_caption.getAnnIds(imgIds=image_id)\n",
    "                captions = coco_caption.loadAnns(ids=caption_ids)\n",
    "                keypoints = coco_keypoint.loadAnns(ids=keypoint_ids)\n",
    "\n",
    "                if full_image:\n",
    "                    data = {'keypoints': [], 'caption': captions.copy(),\n",
    "                            'image': coco_keypoint.loadImgs(image_id)[0]}\n",
    "                    for keypoint in keypoints:\n",
    "                        if keypoint.get('num_keypoints') > keypoint_threshold:\n",
    "                            data['keypoints'].append(keypoint.copy())\n",
    "                    if len(data['keypoints']) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # add sentence encoding\n",
    "                    if text_model is not None:\n",
    "                        data['vector'] = [get_caption_vector(text_model, caption.get('caption')) for caption in\n",
    "                                          captions]\n",
    "                    self.dataset.append(data)\n",
    "                else:\n",
    "                    # each person in the image\n",
    "                    for keypoint in keypoints:\n",
    "                        # with enough keypoints\n",
    "                        if keypoint.get('num_keypoints') > keypoint_threshold:\n",
    "                            data = {'keypoint': keypoint.copy(), 'caption': captions.copy(),\n",
    "                                    'image': coco_keypoint.loadImgs(image_id)[0]}\n",
    "\n",
    "                            # add sentence encoding\n",
    "                            if text_model is not None:\n",
    "                                data['vector'] = [get_caption_vector(text_model, caption.get('caption')) for caption in\n",
    "                                                  captions]\n",
    "                            self.dataset.append(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    # return either individual heatmap of heatmap of a whole image\n",
    "    def get_heatmap(self, data, augment=True):\n",
    "        if self.full_image:\n",
    "            return get_full_image_heatmap(data.get('image'), data.get('keypoints'), augment)\n",
    "        else:\n",
    "            return get_heatmap(data.get('keypoint'), augment)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        item = dict()\n",
    "\n",
    "        if self.for_regression:\n",
    "            item['coordinates'] = torch.tensor(get_augmented_coordinates(data.get('keypoint')), dtype=torch.float32)\n",
    "        else:\n",
    "            # change heatmap range from [0,1] to[-1,1]\n",
    "            item['heatmap'] = torch.tensor(self.get_heatmap(data) * 2 - 1, dtype=torch.float32)\n",
    "\n",
    "        if self.with_vector:\n",
    "            # randomly select from all matching captions\n",
    "            item['vector'] = torch.tensor(random.choice(data.get('vector')), dtype=torch.float32)\n",
    "            if not self.for_regression:\n",
    "                item['vector'].unsqueeze_(-1).unsqueeze_(-1)\n",
    "        return item\n",
    "\n",
    "    # get a batch of random caption sentence vectors from the whole dataset\n",
    "    def get_random_caption_tensor(self, number):\n",
    "        vector_tensor = torch.empty((number, sentence_vector_size), dtype=torch.float32)\n",
    "\n",
    "        if self.with_vector:\n",
    "            for i in range(number):\n",
    "                # randomly select from all captions\n",
    "                vector = random.choice(random.choice(self.dataset).get('vector'))\n",
    "                vector_tensor[i] = torch.tensor(vector, dtype=torch.float32)\n",
    "\n",
    "        if self.for_regression:\n",
    "            return vector_tensor\n",
    "        else:\n",
    "            return vector_tensor.unsqueeze_(-1).unsqueeze_(-1)\n",
    "\n",
    "    # get a batch of random heatmaps and captions from the whole dataset\n",
    "    def get_random_heatmap_with_caption(self, number):\n",
    "        caption = []\n",
    "        heatmap = torch.empty((number, total_keypoints, heatmap_size, heatmap_size), dtype=torch.float32)\n",
    "\n",
    "        for i in range(number):\n",
    "            # randomly select from all images\n",
    "            data = random.choice(self.dataset)\n",
    "            heatmap[i] = torch.tensor(self.get_heatmap(data, augment=False) * 2 - 1, dtype=torch.float32)\n",
    "            caption.append(random.choice(data.get('caption')).get('caption'))\n",
    "\n",
    "        return {'heatmap': heatmap, 'caption': caption}\n",
    "\n",
    "    # get a batch of random coordinates and captions from the whole dataset\n",
    "    def get_random_coordinates_with_caption(self, number):\n",
    "        caption = []\n",
    "        coordinates = torch.empty((number, total_keypoints * 3), dtype=torch.float32)\n",
    "\n",
    "        for i in range(number):\n",
    "            # randomly select from all images\n",
    "            data = random.choice(self.dataset)\n",
    "            coordinates[i] = torch.tensor(get_augmented_coordinates(data.get('keypoint')), dtype=torch.float32)\n",
    "            caption.append(random.choice(data.get('caption')).get('caption'))\n",
    "\n",
    "        return {'coordinates': coordinates, 'caption': caption}\n",
    "\n",
    "    # get a batch of random interpolated caption sentence vectors from the whole dataset\n",
    "    def get_interpolated_caption_tensor(self, number):\n",
    "        vector_tensor = torch.empty((number, sentence_vector_size), dtype=torch.float32)\n",
    "\n",
    "        if self.with_vector:\n",
    "            for i in range(number):\n",
    "                # randomly select 2 captions from all captions\n",
    "                vector = random.choice(random.choice(self.dataset).get('vector'))\n",
    "                vector2 = random.choice(random.choice(self.dataset).get('vector'))\n",
    "\n",
    "                # interpolate caption sentence vectors\n",
    "                interpolated_vector = beta * vector + (1 - beta) * vector2\n",
    "                vector_tensor[i] = torch.tensor(interpolated_vector, dtype=torch.float32)\n",
    "\n",
    "        if self.for_regression:\n",
    "            return vector_tensor\n",
    "        else:\n",
    "            return vector_tensor.unsqueeze_(-1).unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "caption_path = '/home/birdy/datasets/coco/annotations/captions_train2017.json'\n",
    "keypoint_path = '/home/birdy/datasets/coco/annotations/person_keypoints_train2017.json'\n",
    "text_model_path = '/home/birdy/amazon_review_polarity.bin'\n",
    "text_model = fasttext.load_model(text_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.21s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=13.96s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birdy/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "multi = False\n",
    "coco_caption = COCO(caption_path)\n",
    "coco_keypoint = COCO(keypoint_path)\n",
    "dataset = HeatmapDataset(coco_keypoint, coco_caption, single_person=not multi, text_model=text_model, full_image=multi)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch = next(iter(data_loader))\n",
    "print(len(real_batch['heatmap'].to(device)[:64]))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
